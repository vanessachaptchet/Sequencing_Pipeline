Parfait üëç
Voici **TOUT le contenu du README**, **cl√© en main**.
üëâ Tu **copies‚Äìcolles exactement** ceci dans `README.md`.
üëâ **Tu ne modifies rien** si tu ne veux pas.

---

````markdown
# Sequencing Run Processing Pipeline (Prototype)

## Kontext und Ziel
Dieses Projekt wurde im Rahmen einer technischen Aufgabe f√ºr die Position  
**Junior Bioinformatiker / Data Scientist** entwickelt.

Ziel dieser Aufgabe ist die Konzeption und Implementierung einer einfachen,
aber robusten Verarbeitungskomponente f√ºr Sequenzierl√§ufe mit Fokus auf:

- saubere und nachvollziehbare Code-Struktur  
- robuste Fehlerbehandlung  
- klare Statusberichterstattung  
- gute Wartbarkeit und Erweiterbarkeit  

Der Schwerpunkt liegt nicht auf biologischer Komplexit√§t, sondern auf
Software-Engineering-Prinzipien, wie sie in bioinformatischen Pipelines
im Produktionsumfeld angewendet werden.

---

## Grundlegender Ansatz
Die Pipeline verarbeitet Sequenzierdaten in einer klaren Hierarchie:

- Das **Input-Verzeichnis** enth√§lt mehrere Sequenzierl√§ufe (Runs)
- Jeder **Run** besteht aus mehreren FASTQ-Dateien (Samples)
- Jedes Sample wird **unabh√§ngig** verarbeitet
- Fehler auf Sample-Ebene stoppen **nicht** den gesamten Run

Durch diesen Ansatz ist die Pipeline robust gegen√ºber fehlerhaften oder
inkompletten Eingabedaten und kann auch **Teilergebnisse** korrekt verarbeiten.
Runs k√∂nnen daher den Status **SUCCESS**, **FAILED** oder **PARTIAL** annehmen.

---

## Projektstruktur
Der Code ist modular aufgebaut, um Verantwortlichkeiten klar zu trennen:

- `main.py`  
  Einstiegspunkt der Anwendung.  
  Verarbeitet Kommandozeilenargumente, initialisiert das Logging und steuert
  den gesamten Ablauf der Pipeline.

- `processor/run_scanner.py`  
  Erkennt Sequenzierl√§ufe und FASTQ-Dateien im Input-Verzeichnis.

- `processor/fastq_utils.py`  
  Liest FASTQ-Dateien und berechnet einfache technische Metriken
  (z. B. Anzahl der Reads, durchschnittliche Read-L√§nge).

- `processor/sample_processor.py`  
  Verarbeitet einzelne FASTQ-Samples und kapselt die Sample-spezifische
  Fehlerbehandlung.

- `processor/output_writer.py`  
  Aggregiert die Ergebnisse auf Run-Ebene und erzeugt strukturierte
  JSON-Ausgabedateien.

- `processor/logging_utils.py`  
  Konfiguriert das Logging f√ºr Konsolenausgabe und Logdateien.

---

## Ausf√ºhrung der Pipeline

```bash
python main.py --input input --outdir output --log logs/pipeline.log
````

### Annahmen zum Input

* `--input` enth√§lt ein Verzeichnis pro Sequenzierlauf (z. B. `20251212_run001`)
* FASTQ-Dateien k√∂nnen sich in Unterverzeichnissen befinden (rekursive Suche)
* Unterst√ºtzte Dateiformate:

  * `.fastq`
  * `.fq`
  * `.fastq.gz`
  * `.fq.gz`
* Technische Verzeichnisse (z. B. `output`, `logs`, `processor`) werden
  bei der Run-Erkennung ignoriert

---

## Ausgaben

### Run-√úbersicht (erforderlich)

Die Datei `output/status_overview.json` enth√§lt eine √úbersicht pro Run mit:

* `run_id`
* `num_samples`
* `run_status` (SUCCESS / FAILED / PARTIAL)
* `failed_samples`

Diese Datei eignet sich f√ºr ein schnelles Monitoring oder die Weiterverarbeitung
in nachgelagerten Systemen.

### Detaillierter Bericht (Nachvollziehbarkeit)

Die Datei `output/status_detailed.json` enth√§lt detaillierte Informationen
auf Sample-Ebene:

* Sample-ID
* Verarbeitungsstatus
* berechnete Metriken bei erfolgreicher Verarbeitung
* Fehlermeldung bei fehlgeschlagenen Samples

---

## Fehlerbehandlungsstrategie

* Jedes FASTQ-Sample wird unabh√§ngig verarbeitet
* Besch√§digte oder unvollst√§ndige FASTQ-Dateien f√ºhren zu einem FAILED-Sample
* Fehler werden mit Run-ID und Sample-ID geloggt
* Der Run-Status wird wie folgt bestimmt:

  * **SUCCESS**: alle Samples erfolgreich verarbeitet
  * **FAILED**: alle Samples fehlgeschlagen
  * **PARTIAL**: Mischung aus erfolgreichen und fehlgeschlagenen Samples

Dieser Ansatz stellt sicher, dass Probleme transparent sichtbar sind
und nutzbare Ergebnisse nicht verloren gehen.

---

## Monitoring und Produktionsaspekte (konzeptionell)

In einer produktiven Umgebung k√∂nnten unter anderem folgende Metriken
√ºberwacht werden:

* Anzahl verarbeiteter Runs und Samples
* Anteil FAILED und PARTIAL Runs
* H√§ufigkeit bestimmter Fehlertypen (z. B. besch√§digte FASTQ-Dateien)
* Verarbeitungsdauer pro Run und pro Sample

M√∂gliche Alarmierungsstrategien:

* Alarm bei √úberschreiten definierter Fehlerraten
* Alarm, wenn Runs ungew√∂hnlich lange in Bearbeitung bleiben

Geeignete Werkzeuge:

* **Prometheus + Grafana** f√ºr Metriken und Dashboards
* **ELK / EFK Stack** f√ºr zentrales Logging
* Benachrichtigungen √ºber E-Mail, Slack oder PagerDuty

---

## M√∂gliche Erweiterungen

* Erg√§nzung von Unit-Tests f√ºr FASTQ-Verarbeitung und Statuslogik
* Parallele Verarbeitung gro√üer Runs
* Optionale CSV-Ausgabe zus√§tzlich zu JSON
* Integrit√§tspr√ºfungen (z. B. Checksummen)
* Bereitstellung der Pipeline √ºber Docker oder Conda

